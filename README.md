# Image-to-Braille-Converter-for-Visually-Challenged-People
Navigation and daily routine work through the unfamiliar environment remain a significant issue for blind people. Despite various technological advancements, very little work has been done in this domain. To overcome the challenges of these people, the proposed framework can help blind people to understand their surrounding environment effectively. This system performs the purpose of converting images to Braille signals.
This work sits at the intersection of deep learning, Natural Language Processing (NLP), Artificial Intelligence and IoT. 

In this framework, first, an image of the scene is captured. Next, the image is captioned using the CNN model. Finally, from the captured image, a braille robotic signal and speech are generated with IoT and NLP's help. To demonstrate the utility of the framework, it has been implemented in a real-world scenario using an IoT kit.
Flickr8K dataset has been used for this project. This dataset comprises over 8,000 images, each of which is paired with five different captions.

For the Hardware Implementation of this project, the output of the CNN Model is used as an input for the purpose of displaying the Braille notation. Using a basic algorithm we are using the captions generated by the CNN Model as an input string for the serial monitor. It is hence, flowing the data from our CNN Model into the Arduino.   

Components Used: ArduinoUNO R3, BreadBoard, Jumper Wires (Male-to-Male, Male-to-Female), LEDs, LCD Display, Resistors (220Ω, 2kΩ). 

![Screenshot (72)](https://user-images.githubusercontent.com/97681702/187280689-6b5a67bd-662b-428c-8f51-25e17bc8b787.png)
